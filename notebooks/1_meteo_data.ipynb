{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5889004-11b8-4eeb-9ca8-4bd5800ec98c",
   "metadata": {},
   "source": [
    "### GET WEATHER DATA USING API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98285c67-aff0-4f9b-9a72-9b52bbc521e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import requests\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef321c36-54d8-4406-8971-847f2b69cffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fips_list = [str(x).zfill(2) for x in range(1,61)]\n",
    "for x in ['03', '07', '14', '43', '52', '57', '58', '59']:\n",
    "    fips_list.remove(x)\n",
    "fips_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76744f5-3f13-4eb7-8612-40a5dec66add",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_path = '../data/1_raw/meteo/stations.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d728327b-9904-44bd-b116-42150d1f11c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#column_headers = list(data[0].keys())\n",
    "column_headers = [\n",
    "    'elevation',\n",
    "    'mindate',\n",
    "    'maxdate',\n",
    "    'latitude',\n",
    "    'name',\n",
    "    'datacoverage',\n",
    "    'id',\n",
    "    'elevationUnit',\n",
    "    'longitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25d25cb-d7ab-44ed-9bb9-41c23ce7718e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(stations_path, 'w', newline='') as csv_file:\n",
    "    # Create a CSV writer object\n",
    "    csv_writer = csv.DictWriter(csv_file, fieldnames=column_headers)\n",
    "    \n",
    "    # Write the column headers to the CSV file\n",
    "    csv_writer.writeheader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80da4fbc-8e5b-44e6-be7a-43cf906880d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fips in fips_list:\n",
    "    \n",
    "    offset=0\n",
    "    empty_response = False\n",
    "    \n",
    "    while not empty_response:\n",
    "        url=f'https://www.ncei.noaa.gov/cdo-web/api/v2/stations?locationid=FIPS:{fips}&datacategoryid=TEMP&startdate=2010-01-01&enddate=2022-12-31&limit=1000&offset={offset}'\n",
    "        headers = {'token': 'geenLBYxrnMaVJmsIXldbsCqTQNHfSpH'}\n",
    "    \n",
    "        response = requests.get(url=url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            json_response = response.json()  # Convert response to JSON\n",
    "            \n",
    "            if not json_response:\n",
    "                empty_response = True\n",
    "            else:\n",
    "                data = json_response['results']\n",
    "\n",
    "                with open(stations_path, 'a', newline='') as csv_file:\n",
    "                    # Create a CSV writer object\n",
    "                    csv_writer = csv.DictWriter(csv_file, fieldnames=column_headers)\n",
    "\n",
    "                    # Write each row of data to the CSV file\n",
    "                    for row in data:\n",
    "                        csv_writer.writerow(row)\n",
    "                \n",
    "                offset += 1000\n",
    "\n",
    "    print(f'Data exported for FIPS {fips}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f75118b-d09f-4888-87a6-ffaeace0910a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create file\n",
    "data_gsom_path = '../data/1_raw/meteo/data_gsom.csv'\n",
    "\n",
    "column_headers = ['date', 'datatype', 'station', 'attributes', 'value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc395c23-d74e-4f93-91ed-37bf9c16889f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_gsom_path, 'w', newline='') as csv_file:\n",
    "    # Create a CSV writer object\n",
    "    csv_writer = csv.DictWriter(csv_file, fieldnames=column_headers)\n",
    "    \n",
    "    # Write the column headers to the CSV file\n",
    "    csv_writer.writeheader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0623110c-bf42-4651-a86d-6aeb9c3d29ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(2010, 2023):\n",
    "    for fips in fips_list:\n",
    "        \n",
    "        offset=0\n",
    "        empty_response = False\n",
    "        \n",
    "        while not empty_response:\n",
    "            url=f'https://www.ncei.noaa.gov/cdo-web/api/v2/data?datasetid=GSOM&locationid=FIPS:{fips}&datatypeid=TMAX,TMIN,TAVG&startdate={year}-01-01&enddate={year}-12-31&limit=1000&offset={offset}'\n",
    "            headers = {'token': 'geenLBYxrnMaVJmsIXldbsCqTQNHfSpH'}\n",
    "        \n",
    "            response = requests.get(url=url, headers=headers)\n",
    "            if response.status_code == 200:\n",
    "                json_response = response.json()  # Convert response to JSON\n",
    "                \n",
    "                if not json_response:\n",
    "                    empty_response = True\n",
    "                else:\n",
    "                    data = json_response['results']\n",
    "    \n",
    "                    with open(data_gsom_path, 'a', newline='') as csv_file:\n",
    "                        # Create a CSV writer object\n",
    "                        csv_writer = csv.DictWriter(csv_file, fieldnames=column_headers)\n",
    "    \n",
    "                        # Write each row of data to the CSV file\n",
    "                        for row in data:\n",
    "                            csv_writer.writerow(row)\n",
    "                    \n",
    "                    offset += 1000\n",
    "    \n",
    "        print(f'Data exported for year {year}, FIPS {fips}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e19ad12-318f-4f91-af1b-33ae9857d1bb",
   "metadata": {},
   "source": [
    "### FILTER STATIONS WITH FULL DATA COVERAGE ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd737b21-f76f-4238-949c-8887e39f2597",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stations = pd.read_csv(stations_path)\n",
    "df_stations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d12ceb8-d997-492c-8416-caea5a2c0681",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stations_cols = df_stations.columns.tolist()\n",
    "stations_cols = [\n",
    "    'id', \n",
    "    'name',    \n",
    "    'latitude', \n",
    "    'longitude', \n",
    "    'elevation',\n",
    "    'elevationUnit',    \n",
    "    'mindate',\n",
    "    'maxdate',\n",
    "    'datacoverage',\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97f1e41-b2e8-493f-ae5a-ac0293f0b3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stations = df_stations[stations_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a385c648-9b55-4c03-b962-bc5132ae6df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename some columns\n",
    "df_stations.rename(columns={'id': 'station_id', \n",
    "                            'name': 'station_name',\n",
    "                            'latitude': 'station_lat', \n",
    "                            'longitude': 'station_lon',\n",
    "                            'elevation': 'station_el'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7433a8-77ea-425a-aecd-7f4fa7c9d4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stations_full = df_stations.loc[\n",
    "                            (df_stations['mindate'] <= '2009-12-01')\n",
    "                            & (df_stations['maxdate'] >= '2023-01-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb258ce-1190-45b7-9003-49f8a38f399f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stations_full.to_csv('../data/1_raw/meteo/stations_full_coverage.csv', index=True, index_label='station_idx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317c1597-44b7-43b9-9c22-680b236330ea",
   "metadata": {},
   "source": [
    "### PROCESS WEATHER DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe618e25-6063-49e4-bf32-646c1ea9ec52",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_weather = ['field_1', \n",
    "              'LOCAL_DATE', \n",
    "              'LOCATION_L', \n",
    "              'LOCATION_1', \n",
    "              'station_id', \n",
    "              'station_la', \n",
    "              'station_lo', \n",
    "              'station_el', \n",
    "              'zones']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ce3fb2-73d1-4b23-a5b3-a2f3b12fe888",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_gsom = pd.read_csv(data_gsom_path, header=0)\n",
    "df_data_gsom.shape  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c88f14-57e7-4b56-912e-064e5041bea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_gsom['YYYY-mm'] = pd.to_datetime(df_data_gsom['date']).dt.strftime('%Y-%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e17a7b-1a38-4ad5-a48f-6754a8fad5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename some columns\n",
    "df_data_gsom.rename(columns={'station': 'station_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95e5b2a-dc10-4cf1-a777-0e4efa29f1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather = df_data_gsom.pivot_table(index=['YYYY-mm', 'station_id'], columns='datatype', values='value')\n",
    "df_weather.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3789973d-8d7f-4492-8bd6-b81e88af42ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add station data to weather data\n",
    "df_weather = pd.merge(df_weather, df_stations[['station_lat', 'station_lon', 'station_id']], how='left', on='station_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965559ba-7353-4bd3-8418-673f8a26a57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to csv\n",
    "df_weather.to_csv('../data/1_raw/meteo/weather.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projekt_ed",
   "language": "python",
   "name": "projekt_ed"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
