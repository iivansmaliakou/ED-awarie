{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4201fdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b9e9a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\n",
    "    \"accident_gravity_reporting_regulated_jul2020_present.txt\",\n",
    "    \"accident_hazardous_liquid_jan2010_present.txt\",\n",
    "    \"incident_gas_distribution_jan2010_present.txt\",\n",
    "    \"incident_gas_transmission_gathering_jan2010_present.txt\",\n",
    "    \"incident_liquefied_natural_gas_jan2011_present.txt\",\n",
    "    \"incident_type_r_reporting_regulated_gas_gathering_may2022_present.txt\"\n",
    "]\n",
    "\n",
    "data_sources = [\n",
    "    'gravity',\n",
    "    'hazardous_liquid',\n",
    "    'gas_distribution',\n",
    "    'gas_transmission',\n",
    "    'liquefied_natural_gas',\n",
    "    'gas_gathering'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33548aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8874, 871)\n"
     ]
    }
   ],
   "source": [
    "# concatenate tables to one df\n",
    "\n",
    "df_temp1 = pd.read_csv(\n",
    "    paths[0]\n",
    "    , header=0\n",
    "    , encoding='unicode_escape' \n",
    "    , sep='\\t'\n",
    "    #, index_col=['REPORT_NUMBER', 'SUPPLEMENTAL_NUMBER'] \n",
    "    , engine='python'\n",
    "    )\n",
    "df_temp1['data_source'] = data_sources[0]\n",
    "\n",
    "df_temp2 = pd.read_csv(\n",
    "    paths[1]\n",
    "    , header=0\n",
    "    , encoding='unicode_escape' \n",
    "    , sep='\\t'\n",
    "    #, index_col=['REPORT_NUMBER', 'SUPPLEMENTAL_NUMBER'] \n",
    "    , engine='python'\n",
    "    )\n",
    "df_temp2['data_source'] = data_sources[1]\n",
    "\n",
    "df = pd.concat([df_temp1, df_temp2])\n",
    "\n",
    "\n",
    "for path, data_source in zip(paths[2:], data_sources[2:]):\n",
    "    df_temp = pd.read_csv(\n",
    "        path\n",
    "        , header=0\n",
    "        , encoding='unicode_escape' \n",
    "        , sep='\\t'\n",
    "        #, index_col=['REPORT_NUMBER', 'SUPPLEMENTAL_NUMBER'] \n",
    "        , engine='python'\n",
    "        )\n",
    "    df_temp['data_source'] = data_sources[1]\n",
    "    df = pd.concat([df, df_temp])\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4ac7e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create column 'LOCAL_DATE'\n",
    "df2 = df.copy()\n",
    "df2['LOCAL_DATETIME'] = pd.to_datetime(df2['LOCAL_DATETIME'])\n",
    "df2['LOCAL_DATE'] = df2['LOCAL_DATETIME'].dt.date\n",
    "\n",
    "df = df2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc896f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unnamed columns\n",
    "columns_to_drop = df.columns[df.columns.str.contains('Unnamed')]\n",
    "df = df.loc[:, ~df.columns.isin(columns_to_drop)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4df1569f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out dates outside of our range\n",
    "# and records with no locations\n",
    "df = df[\n",
    "    (df['LOCAL_DATE'] >= datetime.date(2010, 1, 1)) \n",
    "    & (df['LOCAL_DATE'] <= datetime.date(2022, 12, 31))\n",
    "    & (df['LOCATION_LATITUDE'].notnull())\n",
    "    & (df['LOCATION_LONGITUDE'].notnull())\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b817701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate nans per column\n",
    "# filter out those with more than 0.8 nans\n",
    "nan_share_per_column = df.isna().sum()/df.shape[0]\n",
    "cols_nan_less_08 = nan_share_per_column[nan_share_per_column <= 0.8]\n",
    "cols_to_keep = cols_nan_less_08.index.tolist()\n",
    "\n",
    "df3 = df.loc[:, cols_to_keep]\n",
    "df3.to_csv('df_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "befce2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual selection\n",
    "selected_cols = [\n",
    "    'LOCAL_DATE',\n",
    "    'LOCATION_LATITUDE',\n",
    "    'LOCATION_LONGITUDE',\n",
    "    'COMMODITY_RELEASED_TYPE',\n",
    "    'COMMODITY_SUBTYPE',\n",
    "    'UNINTENTIONAL_RELEASE_BBLS',\n",
    "    'INTENTIONAL_RELEASE_BBLS',\n",
    "    'RECOVERED_BBLS',\n",
    "    'FATALITY_IND',\n",
    "    'FATAL',\n",
    "    'INJURY_IND',\n",
    "    'INJURE',\n",
    "    'OPERATOR_TYPE',\n",
    "    'ON_OFF_SHORE',\n",
    "    'IGNITE_IND',\n",
    "    'EXPLODE_IND',\n",
    "    'NUM_PUB_EVACUATED',\n",
    "    'FEDERAL',\n",
    "    'LOCATION_TYPE',\n",
    "    'CROSSING',\n",
    "    'ITEM_INVOLVED',\n",
    "    'PIPE_TYPE',\n",
    "    'PIPE_DIAMETER',\n",
    "    'MATERIAL_INVOLVED',\n",
    "    'WILDLIFE_IMPACT_IND',\n",
    "    'SOIL_CONTAMINATION',\n",
    "    'LONG_TERM_ASSESSMENT',\n",
    "    'REMEDIATION_IND',\n",
    "    'WATER_CONTAM_IND',\n",
    "    'EST_COST_OPER_PAID',\n",
    "    'EST_COST_GAS_RELEASED',\n",
    "    'EST_COST_PROP_DAMAGE',\n",
    "    'EST_COST_EMERGENCY',\n",
    "    'EST_COST_ENVIRONMENTAL',\n",
    "    'EST_COST_OTHER',\n",
    "    'CAUSE',\n",
    "    'CAUSE_DETAILS',\n",
    "    'NARRATIVE',\n",
    "    'data_source',\n",
    "    'SYSTEM_PART_INVOLVED',\n",
    "    'SHUTDOWN_DUE_ACCIDENT_IND',\n",
    "    'SHUTDOWN_EXPLAIN',\n",
    "    'UPSTREAM_VALVE_TYPE_IND',\n",
    "    'DOWNSTREAM_VALVE_TYPE_IND',\n",
    "    'DEPTH_OF_COVER',\n",
    "    'PIPE_FACILITY_TYPE',\n",
    "    'PIPE_WALL_THICKNESS',\n",
    "    'PIPE_SMYS',\n",
    "    'PIPE_SPECIFICATION',\n",
    "    'PIPE_SEAM_TYPE',\n",
    "    'PIPE_MANUFACTURER',\n",
    "    'PIPE_COATING_TYPE',\n",
    "    'INSTALLATION_YEAR',\n",
    "    'MANUFACTURED_YEAR',\n",
    "    'RELEASE_TYPE',\n",
    "    'LEAK_TYPE',\n",
    "    'COULD_BE_HCA',\n",
    "    'COMMODITY_REACHED_HCA',\n",
    "    'ACCIDENT_PSIG',\n",
    "    'MOP_PSIG',\n",
    "    'MOP_CFR_SECTION',\n",
    "    'ACCIDENT_PRESSURE',\n",
    "    'PRESSURE_RESTRICTION_IND',\n",
    "    'LENGTH_SEGMENT_ISOLATED',\n",
    "    'INTERNAL_INSPECTION_IND',\n",
    "    'OPERATION_COMPLICATIONS_IND',\n",
    "    'PIPELINE_FUNCTION',\n",
    "    'SCADA_IN_PLACE_IND',\n",
    "    'SCADA_OPERATING_IND',\n",
    "    'SCADA_FUNCTIONAL_IND',\n",
    "    'SCADA_DETECTION_IND',\n",
    "    'SCADA_CONF_IND',\n",
    "    'CPM_IN_PLACE_IND',\n",
    "    'CPM_OPERATING_IND',\n",
    "    'CPM_FUNCTIONAL_IND',\n",
    "    'CPM_DETECTION_IND',\n",
    "    'CPM_CONF_IND',\n",
    "    'INVESTIGATION_STATUS',\n",
    "    'INVESTIGATION_STATUS_DETAILS',\n",
    "    'EMPLOYEE_DRUG_TEST_IND',\n",
    "    'CONTRACTOR_DRUG_TEST_IND',\n",
    "    'EQ_FAILURE_TYPE',\n",
    "    'UNINTENTIONAL_RELEASE',\n",
    "    'INTENTIONAL_RELEASE',\n",
    "    'CLASS_LOCATION_TYPE',\n",
    "    'EST_COST_UNINTENTIONAL_RELEASE',\n",
    "    'EST_COST_INTENTIONAL_RELEASE'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8640c483",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:, selected_cols]\n",
    "\n",
    "# reset index\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# export to csv\n",
    "df.to_csv('df_awarie_2010-2022.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
